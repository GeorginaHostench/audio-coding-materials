{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNERcyFJ2FynzONxVgOHaao"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Neural coding\n","\n","## References:\n","\n","### Convolutional Neural Networks (CNN)\n","\n","### Convolutional autoencoder\n","A neural network with unsupervised training, which means that we don't need to supply a target function. There is only a training set, which is also the target set. A convolutional autoencoder uses convolutional neural networks. An autoencoder maps the input signal to a lower dimensional representation using its encoder part. In this way it is similar for instance to an audio encoder, which compresses an audio signal into a representation with fewer bits than the original audio signal. The decoder part of an autoencoder maps the lower dimensional representation back into the higher dimensional representation. This is similar to an audio decoder, which decodes the compressed version back to an audio signal. The reconstruction after the decoder part should be as close as possible to the original. Hence the original (the training set) is also the target.\n","\n","### Pytorch\n","PyTorch is an open-source machine learning framework that provides a flexible and efficient platform for building and training deep learning models. It has become one of the most popular deep learning frameworks due to its flexibility, Pythonic interface, and extensive support for GPUs (Graphics Processing Units), which are crucial for accelerating deep learning computations.\n","\n","### Tensor\n","A tensor is a mathematical object that generalizes scalars, vectors, and matrices to higher dimensions. In deep learning and machine learning, a tensor is a data structure that is used to store multi-dimensional data, and it's the basic building block for computations in frameworks like PyTorch and TensorFlow.\n","\n","### Activation function\n","An activation function used in the encoder part of a model, like tanh, helps introduce non-linearity and restricts the encoded output to a range between -1 and 1. The decoder does not use an activation function, which allows the model to reconstruct the input more directly.\n","\n","### Bias\n","In a neural network layer, bias is a learnable parameter added to the output of the convolution (or any other operation, like a fully connected layer). It allows the model to shift the activation function output by some constant amount, helping the model fit the data better.\n","\n","### Loss function\n","A loss function is a mathematical function that measures the difference between the predicted output of a machine learning model and the actual target values (ground truth). It quantifies how \"wrong\" the model's predictions are, guiding the optimization process to adjust the model's parameters to minimize the error. Mean Squared Error (MSE) is a common loss function.\n","\n","### Model weights\n","The parameters within a neural network that the model learns during training. These weights are the values that the model adjusts to better predict the target output from the input data. In deep learning, weights are crucial because they define the strength of connections between neurons in different layers of the network.\n","\n","### Optimizer\n","Algorithm used to adjust the parameters (such as weights and biases) of a model in order to minimize the loss function during training. The optimizer updates the model parameters based on the gradients computed through backpropagation, with the goal of finding the optimal set of parameters that minimize the error between predicted and actual values.\n","\n","### Model predictions\n","\n","\n"],"metadata":{"id":"iIXsz6Z0nX-5"}},{"cell_type":"code","source":["!git clone https://github.com/xserra/audio-coding-materials.git\n","import torch\n","import torch.nn as nn\n","# import torch.nn.functional as F\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import IPython.display as ipd\n","from scipy.io.wavfile import read\n","\n","device = 'cpu'"],"metadata":{"id":"w3AlKSvLr8ey"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# functions used in the whole lab\n","def read_sound(file):\n","  \"\"\" read a mono wav sound file, assuming is mono, and convert it to a floating point array\n","    Args:\n","      file (str): File name\n","    Returns:\n","      sound_array (numpy.array): Array of samples as floating point values between -1 and 1\n","      sampling_rate (int): Sampling rate\n","  \"\"\"\n","  # read sound file\n","  sampling_rate, x = read(file)\n","  # convert to floating point values between -1 and 1, assuming x are 16 bit integers\n","  sound_array = np.float32(x) / 2**15\n","  return sound_array, sampling_rate\n","\n","def display_sound(sound_array, sampling_rate=44100):\n","  \"\"\" Display signal sound_array\n","    Args:\n","      sound_array (numpy.array): Array of samples\n","      sampling_rate (int): Sampling rate\n","  \"\"\"\n","  # plot the waveform of the sound\n","  plt.figure(0, figsize=(10, 4))\n","  time_indexes = np.arange(0, sound_array.size/sampling_rate, 1.0/sampling_rate)\n","  plt.plot(time_indexes, sound_array)\n","  plt.xlabel('time (seconds)')\n","  plt.ylabel('amplitude')\n","  plt.show()\n","  # play the sound\n","  ipd.display(ipd.Audio(data=sound_array, rate=sampling_rate))\n","\n","def signal2pytorch(x):\n","    #Function to convert a signal vector x into a 3-d Tensor that conv1d of Pytorch expects\n","    #Argument x: a 1-d signal as numpy array\n","    #input x[batch,sample]\n","    #output: 3-d Tensor X for conv1d input.\n","    #for conv1d Input: (N,Cin,Lin), Cin: numer of input channels (e.g. for stereo), Lin: length of signal, N: number of Batches (signals)\n","    X = np.expand_dims(x, axis=0)  #add channels dimension (here only 1 channel)\n","    if len(x.shape)==1: #mono:\n","        X = np.expand_dims(X, axis=0)  #add batch dimension (here only 1 batch)\n","    X=torch.from_numpy(X)\n","    X=X.type(torch.Tensor)\n","    X=X.permute(1,0,2)  #make batch dimension first\n","    return X"],"metadata":{"id":"lddkXBoVr_jy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Part 1 - Convolution autoencoder"],"metadata":{"id":"6T5r716-rv6s"}},{"cell_type":"code","source":["# define model graph\n","\n","class Convautoenc(nn.Module):\n","    def __init__(self):\n","        super(Convautoenc, self).__init__()\n","        #Analysis Filterbank with downsampling of N=1024, filter length of 2N, but only N/2 outputs:\n","        self.conv1=nn.Conv1d(in_channels=1, out_channels=32, kernel_size=2048, stride=1024, padding=1023, bias=True) #Padding for 'same' filters (kernel_size/2-1)\n","\n","        #Synthesis filter bank:\n","        self.synconv1=nn.ConvTranspose1d(in_channels=32, out_channels=1, kernel_size=2048, stride=1024, padding=1023, bias=True)\n","\n","    def encoder(self, x):\n","        #Analysis:\n","        x = self.conv1(x)\n","        y = torch.tanh(x)\n","        return y\n","\n","    def decoder(self, y):\n","        #Synthesis:\n","        xrek= self.synconv1(y)\n","        return xrek\n","\n","    def forward(self, x):\n","        y=self.encoder(x)\n","        xrek=self.decoder(y)\n","        return xrek"],"metadata":{"id":"k0U8jajAsLPn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# read training data\n","batch=1\n","audio1, samplerate = read_sound(\"/content/audio-coding-materials/162095-chinese-orchestra-channel-1.wav\")\n","X_train = signal2pytorch(audio1).to(device)\n","display_sound(audio1, samplerate)"],"metadata":{"id":"YtR9UUurs2jA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Generate Model\n","model = Convautoenc().to(device)\n","print('Total number of parameters: %i' % (sum(p.numel() for p in model.parameters() if p.requires_grad)))\n","# loss function used is Mean Square Error\n","loss_fn = nn.MSELoss()\n","\n","Ypred=model(X_train)\n","\n","#length of the signal at the output of the network.\n","outputlen = len(Ypred[0,0,:])\n","print(\"outputlen=\", outputlen)\n","\n","#the target signal with same length as model output\n","Y=X_train[:,:,:outputlen]\n","\n","print(\"Input X.shape =\", X_train.shape)\n","print(\"Target Y.shape =\", Y.shape)\n","print(\"Target Y =\", Y)\n","print(\"Y.type() =\", Y.type())"],"metadata":{"id":"0FOthKkJtHWS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# train model\n","learning_rate = 1e-4\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","\n","Ypred = model(X_train)\n","print(\"Ypred=\", Ypred)\n","\n","# train the model over a number of epochs\n","nepocs = 100\n","for epoch in range(nepocs):\n","  Ypred=model(X_train)\n","  loss=loss_fn(Ypred, Y)\n","  if epoch%10==0:\n","    print(epoch, loss.item())\n","  optimizer.zero_grad()\n","  loss.backward()\n","  optimizer.step()"],"metadata":{"id":"fgZcR99mtMjn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# make predictions using the training set\n","\n","#read obtained weights\n","ww = model.state_dict()\n","print(\"ww=\", ww)\n","\n","#Plot obtained weights:\n","plt.figure(figsize=(10,6))\n","plt.plot(np.transpose(np.array(ww['conv1.weight'][0:1,0,:])))\n","plt.plot(np.transpose(np.array(ww['synconv1.weight'][0:1,0,:])))\n","plt.legend(('Encoder Analysis filter 0', 'Decoder Filter 0'))\n","plt.xlabel('Sample')\n","plt.ylabel('Value')\n","plt.title('Encoder and Decoder Filter Coefficients')\n","plt.grid()\n","\n","# Make Predictions based on the obtained weights, on training set\n","predictions = model(X_train).cpu()\n","predictions = predictions.detach()\n","predictions = np.array(predictions)\n","Y=np.array(Y) #target\n","print(\"predictions.shape=\", predictions.shape)\n","#Plot target signal and output of autoencoder:\n","plt.figure(figsize=(10,6))\n","plt.plot(np.array(Y[0,0,:]))\n","plt.plot(predictions[0,0,:])\n","plt.legend(('Target','Predicted'))\n","plt.title('Target and Predicted Signal')\n","plt.xlabel('Sample')\n","plt.grid()\n","#remove unnecessary dimension for playback\n","xrek=predictions[:,0,:]"],"metadata":{"id":"38bmUMbTtd5_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# play input and predicted sounds\n","display(ipd.Audio(audio1, rate=samplerate))\n","display(ipd.Audio(xrek, rate=samplerate))"],"metadata":{"id":"Bg_5Fv1Kt863"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Questions:**\n","\n","1. Find a good prediction using the least number of epochs"],"metadata":{"id":"9hKglvv0tfMU"}},{"cell_type":"markdown","source":["## Part 2 - Generalization of model"],"metadata":{"id":"-FkAb2bStwdz"}},{"cell_type":"code","source":["#Test on data different from the training one\n","\n","# audio2, samplerate = read_sound(\"/content/audio-coding-materials/162095-chinese-orchestra-channel-2.wav\")\n","audio2, samplerate = read_sound(\"/content/audio-coding-materials/sinewave.wav\")\n","X_test=signal2pytorch(audio2).to(device) #Convert to pytorch format, batch is first dimension\n","\n","# Make Predictions based on the obtained weights, on verification set\n","predictions = model(X_test).cpu()\n","predictions = predictions.detach()\n","predictions = np.array(predictions)\n","plt.figure(figsize=(10,6))\n","plt.plot(np.array(X_test[0,0,:]))\n","plt.plot(predictions[0,0,:])\n","plt.legend(('Original','Predicted'))\n","plt.title('The Original and Predicted Signal')\n","plt.xlabel('Sample')\n","plt.grid()\n","xrek=predictions[:,0,:]"],"metadata":{"id":"tI7PqruLt-w6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#play input and predicted sound\n","display(ipd.Audio(audio2, rate=samplerate))\n","display(ipd.Audio(xrek, rate=samplerate))"],"metadata":{"id":"xtssruSKuHqb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Questions:**\n","\n","1. Explore the generation capability of model."],"metadata":{"id":"oSjvrR1juQsR"}}]}